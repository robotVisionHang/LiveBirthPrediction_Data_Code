{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb83453",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c33505ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install missing libraries if failed to import libraries \n",
    "import torch\n",
    "import torchvision\n",
    "import timm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf47653",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "704d1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAndClinicalModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ImageAndClinicalModel, self).__init__()\n",
    "        \n",
    "        self.clinical_dimension = 16\n",
    "        self.image_model = timm.create_model('tf_efficientnetv2_s_in21ft1k', pretrained=True, in_chans= 2, num_classes= 2)\n",
    "\n",
    "        self.clinical_model = torch.nn.Sequential(\n",
    "                            torch.nn.Linear(self.clinical_dimension, 6836),\n",
    "                            torch.nn.BatchNorm1d(6836),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Dropout(0.012310474179685116),\n",
    "\n",
    "                            torch.nn.Linear(6836, 5657),\n",
    "                            torch.nn.BatchNorm1d(5657),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Dropout(0.06788695883005857),\n",
    "\n",
    "                            torch.nn.Linear(5657, 468),\n",
    "                            torch.nn.BatchNorm1d(468),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Dropout(0.6673239199444652),\n",
    "\n",
    "                            torch.nn.Linear(468, 2) )\n",
    "        \n",
    "    def forward(self, image_feature, clinical_feature):\n",
    "\n",
    "        image_output = self.image_model(image_feature)\n",
    "\n",
    "        clinical_output = self.clinical_model(clinical_feature)\n",
    "\n",
    "        final_output = image_output + clinical_output\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d94a9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageAndClinicalModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b600259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3108, 0.9135],\n",
       "        [7.4740, 4.4265]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size, channel, height, width\n",
    "image_feature = torch.randn(2, 2, 500, 500)\n",
    "clinical_feature = torch.randn(2, 16)\n",
    "\n",
    "model( image_feature, clinical_feature )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c017db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
